# ğŸš¢ Shipping Data Product

A robust end-to-end data product for ingesting, processing, transforming, and serving insights from **Telegram channel data** â€” with a particular focus on **object detection** in shared images using **YOLOv8**, and serving analytical insights via a **FastAPI** API.

---

## ğŸ“Œ Project Overview

The goal is to build a modular and scalable data pipeline that:

- ğŸ“¥ **Ingests** Telegram messages and media (images)
- ğŸ§  **Analyzes** images using YOLOv8 object detection
- ğŸ”„ **Transforms** raw data into clean, analytical tables using **dbt**
- ğŸŒ **Exposes** insights through a high-performance **FastAPI** layer

---

## ğŸ§° Technologies Used

- **Python 3.x** â€“ Core language
- **FastAPI** â€“ For building the analytical API
- **Uvicorn** â€“ ASGI server for FastAPI
- **Psycopg2** â€“ PostgreSQL database adapter
- **PostgreSQL** â€“ Data warehouse for raw and transformed data
- **Docker & Docker Compose** â€“ Environment and service management
- **dbt** â€“ Data transformation and testing
- **Ultralytics YOLOv8** â€“ Deep learning model for image object detection
- **python-dotenv** â€“ Environment variable management

---

## ğŸ“ Project Structure

```
shipping-data-product/
â”œâ”€â”€ telegram_data_dbt/           # dbt project for transformations
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ staging/             # Raw â†’ Clean (e.g., stg_image_detections.sql)
â”‚   â”‚   â””â”€â”€ marts/               # Final data marts (e.g., fct_messages.sql)
â”‚   â”œâ”€â”€ profiles.yml             # DB connection profile
â”‚   â”œâ”€â”€ packages.yml             # dbt package dependencies
â”‚   â””â”€â”€ sources.yml              # Raw source table definitions
â”œâ”€â”€ scripts/                     # Python scripts for ingestion & detection
â”‚   â”œâ”€â”€ data_loader.py           # [Conceptual] Telegram message ingestion
â”‚   â”œâ”€â”€ yolo_detector.py         # YOLO detection + DB loader
â”‚   â””â”€â”€ data/
â”‚       â””â”€â”€ raw/
â”‚           â”œâ”€â”€ telegram_media/    # Raw image lake
â”‚           â””â”€â”€ telegram_messages/ # Raw Telegram message files
â”‚       â””â”€â”€ processed/
â”œâ”€â”€ my_project/                  # FastAPI app
â”‚   â”œâ”€â”€ main.py                  # Entry point for FastAPI
â”‚   â”œâ”€â”€ database.py              # DB connection logic
â”‚   â”œâ”€â”€ schemas.py               # Pydantic request/response models
â”‚   â”œâ”€â”€ crud.py                  # DB query logic
â”‚   â””â”€â”€ models.py                # [Optional] ORM models
â”œâ”€â”€ .env                         # Secrets & config (ignored by Git)
â”œâ”€â”€ docker-compose.yml           # Service definitions
â””â”€â”€ README.md                    # You're reading this!
```

---

## âœ… Features Implemented

### 1. ğŸ”„ Data Ingestion & Object Detection
- **YOLOv8 Image Detection**:
  - Detects objects in raw images using `yolo_detector.py`
  - Auto-skips previously processed images
  - Saves detections (class, confidence, bounding box) to `raw.image_detections` table
  - Includes dummy image generation for testing

### 2. ğŸ” Data Transformation with dbt
- **Source Models**: Recognize raw tables like `raw.telegram_messages`, `raw.image_detections`
- **Staging Models**:
  - `stg_image_detections.sql`: Cleaned version of detection results
  - `stg_image_detections.yml`: Metadata and tests (e.g., `not_null`, `unique`, `dbt_utils.at_least_one`)
- **Marts**:
  - Fact and dimension models like `fct_messages` and `dim_channels`

### 3. ğŸŒ Analytical API (FastAPI)
- **Core Structure**:
  - `main.py`: FastAPI router
  - `crud.py`: Query logic using raw SQL
  - `schemas.py`: Validated data responses with Pydantic
- **Implemented Endpoints**:
  - `GET /api/reports/top-products?limit=10`  
    â†’ Top frequently mentioned â€œproductsâ€ from Telegram messages
  - `GET /api/channels/{channel_name}/activity`  
    â†’ Message activity per day for a given channel
  - `GET /api/search/messages?query=keyword`  
    â†’ Full-text search across messages

---

## ğŸš€ How to Run & Test

### 1. ğŸ§ª Environment Setup

- Install dependencies:
  ```bash
  pip install -r requirements.txt
  ```

- Create a `.env` file:
  ```env
  POSTGRES_DB=your_db
  POSTGRES_USER=your_user
  POSTGRES_PASSWORD=your_password
  POSTGRES_HOST=localhost
  POSTGRES_PORT=5432
  TELEGRAM_API_ID=your_api_id
  TELEGRAM_API_HASH=your_api_hash
  ```

### 2. ğŸ³ Run with Docker

```bash
docker-compose up --build
```

- This will:
  - Launch PostgreSQL
  - Run YOLO object detection
  - Start the FastAPI server

### 3. ğŸ—ï¸ Build dbt Models

```bash
cd telegram_data_dbt
dbt deps
dbt build
```

### 4. ğŸ§ª Test the API

- Open [http://localhost:8000/docs](http://localhost:8000/docs) to access Swagger UI.

- Try:
  - `GET /api/reports/top-products?limit=5`
  - `GET /api/channels/chemed_channel/activity`
  - `GET /api/search/messages?query=paracetamol`

---

## ğŸ”® Next Steps

- âœ… Implement real `data_loader.py` for Telegram scraping
- ğŸ” Improve product recognition using NLP / keyword extraction
- ğŸ§  Add more dbt marts (e.g., `fct_image_detections_aggregated`)
- ğŸ” Add API auth (JWT, OAuth)
- ğŸ”„ CI/CD pipelines (GitHub Actions, etc.)
- ğŸ“Š Integrate BI tools like Metabase or Apache Superset

---

## ğŸ›¡ï¸ Security Notice

> âš ï¸ If you accidentally pushed `.env` to GitHub, remove it from version history and rotate any credentials it contained.

---

## ğŸ“¬ Contact

For questions, contributions, or issues, feel free to open an issue or reach out.
